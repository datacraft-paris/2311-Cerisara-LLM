{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQUynnYBxFwRXTDwCu1oY8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datacraft-paris/2311-Cerisara-LLM/blob/main/LowRankCompression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. [Introduction](https://www.google.com/)\n",
        "2. [A Brief Overview of LLMs](https://colab.research.google.com/github/datacraft-paris/2311-Cerisara-LLM/blob/main/LLMs.ipynb)\n",
        "3. [Preparing the data](https://colab.research.google.com/github/datacraft-paris/2311-Cerisara-LLM/blob/main/Data.ipynb)\n",
        "4. Low-Rank Approximation (This notebook)\n",
        "    1. [Recall](#recall)\n",
        "    2. [Setup](#setup)\n",
        "    3. [Low-Rank Linear](#lrl)\n",
        "    4. [~22% Reduction](#reduction)"
      ],
      "metadata": {
        "id": "W2X1kDjKQcQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will explore in this notebook a classic low-rank decomposition applied to LLMs. You will see that it doesn't work very well... but it's an experience that will give us a solid basis for the next notebook."
      ],
      "metadata": {
        "id": "uRoq34ibPo1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recall <a name=\"recal\"></a>"
      ],
      "metadata": {
        "id": "GQmWR9qVodmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A linear function is defined by a matrix $W$:\n",
        "\n",
        "\n",
        "> $$f(X) = XW\n",
        "$$\n",
        "With $X \\in \\mathbb{R}^{b*d_{1}}$ and $\\mathbb{R}^{d_{1}*d_{2}}$.\n",
        "\n",
        "\n",
        "We want to compress the pretrained matrix $W \\in \\mathbb{R}^{d_{1} * d_{2}}$. One way to achieve this is by using Low-Rank Approximation of $W$:\n",
        "\n",
        "> $$\n",
        "W = W_{1}W_{2}\n",
        "$$\n",
        "where $W_{1} \\in \\mathbb{R}^{d_{1} * r}$ and $W_{2} \\in \\mathbb{R}^{r * d_{2}}$.\n",
        "\n",
        "The value $r$ is the rank of the approximating matrices, this number should be chosen such that the total number of parameters in $W_{1}$ and $W_{2}$ is lower than the number of parameters in $W$.\n",
        "\n",
        "The question now is how to get $W_{1}$ and $W_{2}$. One way to estimate these matrices is using SVD. SVD offers the best $r$-rank approximation the matrix $W$:\n",
        "\n",
        "> $$\n",
        "W = USV^{T}\n",
        "$$\n",
        "where $U \\in \\mathbb{R}^{d_{1} * d_{2}}$ and $V \\in \\mathbb{R}^{d_{2} * d_{2}}$ are orthogonal matrices. $S \\in \\mathbb{R}^{d_{1} * d_{2}}$ is a diagonal matrix wich entries contains singular values in deacrising order.\n",
        "\n",
        "By selecting the largest $r$ terms of the singular values, the resulting matrix is an optimal approximation of W with a lower rank $r$:\n",
        "\n",
        "$$\n",
        "W = U_{:, r}(S_{r:r}V_{:r, :}^{T})\n",
        "$$\n",
        "Where:\n",
        "\n",
        "$$\n",
        "U_{:, r} = W_{1}\n",
        "$$\n",
        "\n",
        "$$\n",
        "(S_{r:r}V_{:r, :}^{T}) = W_{2}\n",
        "$$\n",
        "\n",
        "Now we have $W_{1}$ and $W_{2}$, we can define the linear function as:\n",
        "\n",
        "$$\n",
        "f(X) = XW_{1}W_{2}\n",
        "$$"
      ],
      "metadata": {
        "id": "CkzYeqb8qYkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup <a name=\"setup\"></a>"
      ],
      "metadata": {
        "id": "ZG-9m6nLsBbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip uninstall -y transformers\n",
        "!pip install git+https://github.com/huggingface/transformers accelerate tiktoken"
      ],
      "metadata": {
        "id": "xq3fv2-s1MYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ],
      "metadata": {
        "id": "ExEamjL7sEWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AutoModelForCausalLM.from_pretrained(\"stabilityai/stablelm-3b-4e1t\",\n",
        "                                           torch_dtype=torch.bfloat16,\n",
        "                                           device_map=\"cuda\",\n",
        "                                           trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-3b-4e1t\",\n",
        "                                          trust_remote_code=True)"
      ],
      "metadata": {
        "id": "HqKfSlPcxjuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_llm = copy.deepcopy(llm)"
      ],
      "metadata": {
        "id": "f7mHqt0gyNe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Low-Rank Linear <a name=\"lrl\"></a>"
      ],
      "metadata": {
        "id": "M7Drm_cGx7nH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we write a Low-Rank Linear class, let's take a quick example."
      ],
      "metadata": {
        "id": "ThFOLJpxkIb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "SfrYzMkAl9RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrained matrix\n",
        "W = torch.rand((128, 128))\n",
        "W.requires_grad = False\n",
        "# rank\n",
        "r = 16"
      ],
      "metadata": {
        "id": "eoEIE6eGj_jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the documentation of the SVD implementation of PyTorch: https://pytorch.org/docs/stable/generated/torch.linalg.svd.html\n",
        "\n",
        "Then, call this function to get the U, S and V matrices:"
      ],
      "metadata": {
        "id": "dxyWLSY5kj3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u, s, v = \"TODO\"\n",
        "# diagonalize 's':\n",
        "s = torch.diag(s)"
      ],
      "metadata": {
        "id": "-cAJyFDhkFuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on above formula, get the $W_{1}$ and $W_{2}$"
      ],
      "metadata": {
        "id": "kN3FyZ0flFQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = u[:, :r]\n",
        "w2 = \"TODO\""
      ],
      "metadata": {
        "id": "sIIC68CUlXMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UoWdiu-r6B_"
      },
      "outputs": [],
      "source": [
        "class LowRankLinear(torch.nn.Module):\n",
        "    def __init__(self, w, rank):\n",
        "        super().__init__()\n",
        "        self._decompose(w, rank)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _decompose(self, w, r):\n",
        "        u, s, v = torch.linalg.svd(w.to(dtype=torch.float32))\n",
        "        w1 = (u[:, :r]).to(dtype=torch.bfloat16)\n",
        "        w2 = \"TODO\"\n",
        "        self.w1 = torch.nn.Parameter(w1)\n",
        "        self.w2 = torch.nn.Parameter(w2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return \"TODO\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ~22% Reduction <a name=\"reduction\"></a>"
      ],
      "metadata": {
        "id": "d0dK8-Li38vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"q_proj\": 384,\n",
        "    \"o_proj\": 384,\n",
        "    \"gate_proj\": 512,\n",
        "}"
      ],
      "metadata": {
        "id": "S5ErMWLIyquN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setmodule(module, target_module, value):\n",
        "    \"\"\"Set a target module from in a given module.\"\"\"\n",
        "    submodules = target_module.split(\".\", 1)\n",
        "    if len(submodules) == 1:\n",
        "        setattr(module, submodules[0], value)\n",
        "    else:\n",
        "        setmodule(getattr(module, submodules[0]), submodules[-1], value)"
      ],
      "metadata": {
        "id": "fjYtHsB8yk1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lowrank_model(config, model):\n",
        "    total = sum(1 for _ in model.named_modules())\n",
        "    for name, module in tqdm(model.named_modules(), total=total):\n",
        "        module_name = name.split(\".\")[-1]\n",
        "        if module_name in config:\n",
        "            rank = config[module_name]\n",
        "            lowrank_linear = LowRankLinear(w=module.weight, rank=rank)\n",
        "            setmodule(model, name, lowrank_linear)"
      ],
      "metadata": {
        "id": "0_aetpMrzNzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lowrank_model(config, lr_llm)"
      ],
      "metadata": {
        "id": "FBm8XY2l0INb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of parameters of the Base LLM: {llm.num_parameters(only_trainable=True):,}')\n",
        "print(f'Number of parameters of the Low-Rank LLM: {lr_llm.num_parameters(only_trainable=True):,}')"
      ],
      "metadata": {
        "id": "K_PKtniM131v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\", model=lr_llm, tokenizer=tokenizer, do_sample=False)\n",
        "print(pipe(\"Here a python function that sum up 3 numbers:\", max_new_tokens=32, min_new_tokens=8)[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "mu9dArMP2yEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\", model=llm, tokenizer=tokenizer, do_sample=True)\n",
        "print(pipe(\"One day, I will\", max_new_tokens=16, min_new_tokens=8)[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "cy_0pO_SKBN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2DL_4xqPvEms"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}